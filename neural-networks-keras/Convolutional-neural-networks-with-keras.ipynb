{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales convolucionales surgen a partir de buscar modelos que puedan caracterizar una imagen de un mismo objeto sin importar su rotacion o traslación.\n",
    "Estas redes a diferencia de las redes neuronales perceptrón multicapa, involucran 2 nuevos conceptos: capas de convolución y capas de pooling.\n",
    "En las capas de convolución básicamente se aplica un filtro a la imágen que resalta distintos rasgos, estos dependen del kernel utilizado. Despues de las capas de convolución se suele ocupar una capa de pooling, dependiendo del tipo de pooling es la operación a realizar, pero todos consisten en obtener algo significativo de un bloque de datos.\n",
    "Finalmente, se llega a las capas densas donde se encuentra la interconexión de todas las neuronas, pudiendo relacionar así cada uno de los rasgos obtenidos con su etiqueta correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nbfAnboFaTyb",
    "outputId": "159fd9b6-c6a8-4a41-975c-823228167693"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2y0VwkX0ac-e"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() #Descarga un dataset de prueba\n",
    "    #este es un dataset de 60000 imágenes de 28x28 en escala de grises de los 10 dígitos\n",
    "    #junto con 10000 imagenes más para la validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Np0al_jRae03",
    "outputId": "b8bc8987-27a9-4896-d291-cf9a9448f770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 => [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# transforma las etiquetas en one-hot-encoded vectors\n",
    "num_classes = len(np.unique(y_train)) #Obtiene el número de clases diferentes\n",
    "print(y_train[0], end=' => ') #Muestra la etiqueta del primer elemento de entrenamiento\n",
    "y_train = keras.utils.to_categorical(y_train, 10) #Convierte los valores a variables\n",
    "    #categóricas, asignando un arreglo de 10 elementos y solo uno de ellos es igual a 1,\n",
    "    #los demás son ceros. La posición donde se encuentra el 1 corresponde al valor de y\n",
    "y_test = keras.utils.to_categorical(y_test, 10) #realiza lo mismo para los datos de validación\n",
    "print(y_train[0]) #imprime como se ve ahora la etiqueta del primer elemento de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XndplEL7ag0u",
    "outputId": "b6faa61d-bb85-47f9-8259-dbc398873194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# reescala 0-1 y convierte los datos de entrenamiento a float32\n",
    "X_train = X_train.astype(np.float32) / 255 #ya que el valor de las imagenes correponde a un\n",
    "X_test = X_test.astype(np.float32) / 255 #número entero entre 0-255, los convierte a 0-1\n",
    "                                        #y flotante de 32 bits.\n",
    "# cambia la forma de los datos\n",
    "#la dimension de X_train es (60000,28,28), despues de los cambios es (60000,28,28,1)\n",
    "img_rows, img_cols = X_train.shape[1:] #el primer valor de X_train.shape corresponde al numero de\n",
    "        #elementos, entonces, al saltarse el primer valor obtiene la dimensión de cada uno\n",
    "        #de los elementos.\n",
    "X_train = X_train.reshape(len(X_train), img_rows, img_cols, 1) #asigna una dimensión extra\n",
    "X_test = X_test.reshape(len(X_test), img_rows, img_cols, 1) #asigna una dimensión extra\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1) #crea un vector con la forma de los elementos\n",
    "print(input_shape) #de X_train (se usa en la creación de la primera capa de la red) y lo imprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wI6eDTO4a6b1"
   },
   "outputs": [],
   "source": [
    "#En este bloque de código se establece la arquitectura de la red\n",
    "#Se añaden cada una de las capas, y por cada capa se establece el tipo de capa\n",
    "#en caso de las capas convolucionales se establece su tamaño, el kernel y la función de activación\n",
    "#para las capas de pooling se establece el tipo y tamaño de este\n",
    "\n",
    "lenet = Sequential() #Establece el modelo de la red el cual es secuencial\n",
    "\n",
    "# Capa Convolucional C1\n",
    "lenet.add(Conv2D(6, kernel_size=(5, 5), activation='tanh',  #el primer parametro de conv2d\n",
    "                 input_shape=input_shape, padding='same', name='C1')) #corresponde al numero de\n",
    "        #filtros, en este caso son 6, el kernel es de 5x5, su función de activación es la\n",
    "        #tangente hiperbólica, el tamaño de entrada corresponde al de las imágenes. El padding \n",
    "        #puede ser \"same\" o \"valid\" para el caso de \"same\", agrega ceros en los extremos de tal \n",
    "        #manera que el tamaño de la salida es \"igual\" que el de entrada. Para el caso de \"valid\" \n",
    "        #no agrega ceros y el tamaño de salida suele ser menor al de la entrada.\n",
    "        #la entrada es de 28x28 y la salida de 28x28x6\n",
    "\n",
    "# Capa de Pooling S2\n",
    "lenet.add(AveragePooling2D(pool_size=(2, 2), name='S2')) #el tipo de pooling es de promedio y\n",
    "        #su tamaño es de 2x2, la dimensión pasa de 28x28x6 a 14x14x6\n",
    "\n",
    "# Capa Convolutional C3\n",
    "lenet.add(Conv2D(16, kernel_size=(5, 5), activation='tanh', name='C3')) #capa de convolucion\n",
    "    #con 16 filtros, kernel de 5x5 \"valid\" por lo que su salida es de 10x10.\n",
    "    #la dimension pasa de 14x14x6 a 10x10x16\n",
    "\n",
    "# Capa de Pooling S4\n",
    "lenet.add(AveragePooling2D(pool_size=(2, 2), name='S4')) #capa de pooling utilizando el promedio\n",
    "    #de tamaño de 2x2, la dimensión pasa de 10x10x96 a 5x5x16\n",
    "    #\n",
    "\n",
    "# Capa convolucional completamente conectada C5\n",
    "lenet.add(Conv2D(120, kernel_size=(5, 5), activation='tanh', name='C5')) #\n",
    "    #aplica 120 filtros y como solo quedan elementos de 5x5, al usar un kernel del mismo tamaño\n",
    "    #el resultado es una dimension de 1x1, entonces pasa de 5x5x16 a 120x1x1\n",
    "\n",
    "#Capa completamente conectada FC6\n",
    "lenet.add(Flatten()) #la capa de flatten aplana la dimensión, es decir, pasa de una dimension\n",
    "    #mayor a una dimensión N, en este caso pasa de 1x1x120 a 120\n",
    "lenet.add(Dense(84, activation='tanh', name='FC6')) #capa que conecta las 120 neuronas anteriores\n",
    "    #con 84\n",
    "\n",
    "#Capa de salida (activación softmax)\n",
    "lenet.add(Dense(10, activation='softmax', name='OUTPUT')) #finalmente, conecta las 84 neuronas\n",
    "    #anteriores con 10 neuronas, esto corresponde con la codificación que se le dio a las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "abwGHbsJa9iW",
    "outputId": "6fc5b0f2-52c3-4dae-d3e7-93ad15390f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "S2 (AveragePooling2D)        (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (AveragePooling2D)        (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "C5 (Conv2D)                  (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "FC6 (Dense)                  (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet.compile(loss=categorical_crossentropy, optimizer='SGD', metrics=['accuracy']) #compila el \n",
    "    #modelo, en el parámetro de loss se establece la función de coste que es lo que el modelo debe \n",
    "    #de calcular como error en el entrenamiento para despues minimmizarlo, en este caso, se usa la \n",
    "    #entropia cruzada categorica la cual se recomienda para clasificar entre 2 o más clases.\n",
    "    #El optimizador se refiere a como es que va a minimizar el error, aqui usa SGD o Stochastic\n",
    "    #Gradient Descent. La métrica busca evaluar la eficiencia del modelo. Aqui usa accuracy \n",
    "    #que es el resultado de las clases correctamente clasificadas entre el total de la prueba.\n",
    "lenet.summary() #Muesta la descripción de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "id": "-eoP-iCZa-YO",
    "outputId": "5ad2b7c5-3380-492f-88cf-6773b606ba4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.8740 - accuracy: 0.7849 - val_loss: 0.3940 - val_accuracy: 0.8932\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.3506 - accuracy: 0.9013 - val_loss: 0.2938 - val_accuracy: 0.9136\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2820 - accuracy: 0.9174 - val_loss: 0.2442 - val_accuracy: 0.9285\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2386 - accuracy: 0.9302 - val_loss: 0.2079 - val_accuracy: 0.9364\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2053 - accuracy: 0.9388 - val_loss: 0.1789 - val_accuracy: 0.9463\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1782 - accuracy: 0.9477 - val_loss: 0.1576 - val_accuracy: 0.9542\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1566 - accuracy: 0.9538 - val_loss: 0.1369 - val_accuracy: 0.9604\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1392 - accuracy: 0.9590 - val_loss: 0.1225 - val_accuracy: 0.9660\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1251 - accuracy: 0.9632 - val_loss: 0.1121 - val_accuracy: 0.9685\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1138 - accuracy: 0.9669 - val_loss: 0.1021 - val_accuracy: 0.9699\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.1047 - accuracy: 0.9694 - val_loss: 0.0929 - val_accuracy: 0.9727\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0969 - accuracy: 0.9719 - val_loss: 0.0865 - val_accuracy: 0.9743\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0902 - accuracy: 0.9735 - val_loss: 0.0823 - val_accuracy: 0.9751\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0844 - accuracy: 0.9754 - val_loss: 0.0775 - val_accuracy: 0.9760\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0794 - accuracy: 0.9765 - val_loss: 0.0757 - val_accuracy: 0.9752\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0751 - accuracy: 0.9779 - val_loss: 0.0705 - val_accuracy: 0.9781\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.9793 - val_loss: 0.0690 - val_accuracy: 0.9782\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0678 - accuracy: 0.9802 - val_loss: 0.0641 - val_accuracy: 0.9791\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0647 - accuracy: 0.9813 - val_loss: 0.0615 - val_accuracy: 0.9803\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.0604 - val_accuracy: 0.9807\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 0.0579 - val_accuracy: 0.9814\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0573 - accuracy: 0.9834 - val_loss: 0.0572 - val_accuracy: 0.9806\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0549 - accuracy: 0.9842 - val_loss: 0.0543 - val_accuracy: 0.9828\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0531 - accuracy: 0.9850 - val_loss: 0.0536 - val_accuracy: 0.9829\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0514 - accuracy: 0.9852 - val_loss: 0.0514 - val_accuracy: 0.9838\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0496 - accuracy: 0.9858 - val_loss: 0.0506 - val_accuracy: 0.9826\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0480 - accuracy: 0.9864 - val_loss: 0.0499 - val_accuracy: 0.9836\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0491 - val_accuracy: 0.9836\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.0473 - val_accuracy: 0.9846\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0438 - accuracy: 0.9878 - val_loss: 0.0472 - val_accuracy: 0.9845\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0426 - accuracy: 0.9883 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 0.0452 - val_accuracy: 0.9848\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0405 - accuracy: 0.9887 - val_loss: 0.0447 - val_accuracy: 0.9854\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.0446 - val_accuracy: 0.9845\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.0443 - val_accuracy: 0.9854\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0375 - accuracy: 0.9892 - val_loss: 0.0460 - val_accuracy: 0.9843\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0366 - accuracy: 0.9898 - val_loss: 0.0426 - val_accuracy: 0.9864\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0357 - accuracy: 0.9901 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0348 - accuracy: 0.9901 - val_loss: 0.0409 - val_accuracy: 0.9861\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0341 - accuracy: 0.9907 - val_loss: 0.0418 - val_accuracy: 0.9862\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0404 - val_accuracy: 0.9864\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0408 - val_accuracy: 0.9856\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.0401 - val_accuracy: 0.9862\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0311 - accuracy: 0.9914 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.0391 - val_accuracy: 0.9869\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0300 - accuracy: 0.9916 - val_loss: 0.0390 - val_accuracy: 0.9864\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0293 - accuracy: 0.9924 - val_loss: 0.0379 - val_accuracy: 0.9869\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.0389 - val_accuracy: 0.9864\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 0.0382 - val_accuracy: 0.9873\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 0.0377 - val_accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "#En este bloque de código se realiza el entrenamiento de la red, este llevó bastante tiempo, casi\n",
    "#10 minutos.\n",
    "batch_size = 64 #corresponde al número de muestras que se introduciran al mismo tiempo a la red\n",
    "epochs = 50 #este es el número de epocas de entrenamiento\n",
    "history = lenet.fit(X_train, y_train, #recibe los datos de entrenamiento\n",
    "                      batch_size=batch_size, #el tamaño del batch\n",
    "                      epochs=epochs, #el número de epocas\n",
    "                      validation_data=(X_test, #los datos de validación\n",
    "                                       y_test)) #con sus respectivas etiquetas."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LeNet5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
